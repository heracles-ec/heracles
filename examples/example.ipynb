{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-point statistics from *Heracles*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how *Heracles* extracts the two-point statistics from a *LE3-WL* shear catalogue.\n",
    "\n",
    "The statistics are done here at a much lower resolution than for the scientific goals of *Euclid*. That is because at the target resolution of *NSIDE = 4K* for the position and shear maps (1.5G per map) and *NSIDE = 8K* for the visibility and weight maps (6G per map), the memory required makes it impossible to hold all maps at once. In an actual pipeline, each map is constructed in isolation by a separate worker instance, and each worker only holds the data it requires at each step.\n",
    "\n",
    "The example uses the [*Flagship2* data for *LE3-WL*](https://sdcuk-webdav.roe.ac.uk/LE3_WL_Flagship2/). The catalogue contains about 128 million galaxies, roughly corresponding to *Euclid* DR1 in the north."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p><strong>Note:</strong> This notebook is meant to give you an idea of <strong>how <em>Heracles</em> works</strong>.</p>\n",
    "    <p><ul>\n",
    "        <li>The notebook does <strong>not</strong> perform a very thorough analysis.</li>\n",
    "        <li>The notebook does <strong>not</strong> show everything that <em>Heracles</em> can do.</li>\n",
    "        <li>The notebook does <strong>not</strong> indicate how good the eventual <em>Euclid</em> results may or may not be.</li>\n",
    "        <li>The notebook does <strong>not</strong> treat all observational effects we know about.</li>\n",
    "        <li>The notebook does <strong>not</strong> model the expected signal properly.</li>\n",
    "    </ul></p>\n",
    "    <p><strong>This is a toy, treat it is such!</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "\n",
    "* [Setup](#Setup)\n",
    "* [Basic parameters](#Basic-parameters)\n",
    "* [Catalogues](#Catalogues)\n",
    "* [Tomographic binning](#Tomographic-binning)\n",
    "* [Visibility maps](#Visibility-maps)\n",
    "* [Maps](#Maps)\n",
    "* [Alms](#Alms)\n",
    "* [Two-point statistics](#Two-point-statistics)\n",
    "* [Noise bias](#Noise-bias)\n",
    "* [Debiasing](#Debiasing)\n",
    "* [Mixing matrices](#Mixing-matrices)\n",
    "* [Theory](#Theory)\n",
    "* [Results](#Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this to enable info-level logging. This produces quite a lot of output below, but will show exactly what is going on while you are waiting for results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some required imports, nothing fancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "import fitsio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As initially mentioned, set this to values such that your machine does not blow up when this example keeps all maps in memory at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 1024\n",
    "lmax = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalogues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Heracles* provides a flexible interface for loading catalogues from FITS files or arrays. It also provides a base that can quickly be extended e.g. to databases or more.\n",
    "\n",
    "Here we use the FITS interface to read a catalogue from file. We could specify the columns to read, but we don't do that here, because the catalogue only has columns of interest here.\n",
    "\n",
    "Catalogues are never read into memory all at once. The `page_size` property determines how many rows are read at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.catalog import FitsCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the FITS catalogue\n",
    "wlfs2_cat = FitsCatalog('wlfs2_dr1n_vis24.5_nomag.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `.add_filter()` method, we could add filters to the catalogue here which e.g. strip rows with invalid values, or apply an extra footprint mask to the catalogue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Catalog` interface is essentially an interator over pages of catalogue data. You can use it as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 0\n",
    "for page in wlfs2_cat:\n",
    "    nrows += page.size\n",
    "\n",
    "# no need to iterate to get the number of rows, really\n",
    "assert nrows == wlfs2_cat.size\n",
    "\n",
    "print(f'there are {nrows:_} rows in your catalogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `page` object is a mapping of column names to rows, with some additional features:\n",
    "\n",
    "* The number of rows, `page.size`\n",
    "* The names of columns, `page.names`\n",
    "* A view of the underlying data, `page.data`\n",
    "* Make a copy of the page, `page.copy()`\n",
    "* Delete specific rows, `page.delete(where)`\n",
    "* Return multiple columns at once, using `page['a', 'b']` or `page[['a', 'b']]`\n",
    "* Return columns while checking for invalid values using `page.get('a', 'b')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The position statistics require knowledge of the *a priori* probability of detecting a galaxy at each point in the sky. We call this the *visibility*, and we use it in the form of *visibility maps*, which are full-sky maps of detection probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap = hp.read_map('vmap_wlfs2_dr1n_vis24.5_nomag.fits')\n",
    "\n",
    "# fix UNSEEN pixels to zero and rescale to nside\n",
    "vmap[vmap == hp.UNSEEN] = 0.\n",
    "vmap = hp.ud_grade(vmap, 2*nside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a real survey, the visibility is a complicated function of position, observing conditions, and selection. Each tomographic bin would thus normally require an individual visibility map. However, in this simulated example, the selection is the same for all positions and tomographic bins, and the visibility map is simply the footprint map of the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set visibility map of entire catalogue\n",
    "wlfs2_cat.visibility = vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick inspection of the visibility map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(vmap, title='visibility', cmap='binary', bgcolor='none')\n",
    "hp.graticule()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tomographic binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `wlfs2_cat` object can be used to read the entire catalogue. However, we would like to split our galaxies into individual tomographic bins. In fact, each galaxy has already been assigned a label that says which tomographic bin it belongs to, in the `TOM_BIN_ID` column.\n",
    "\n",
    "To perform the tomographic binning, we construct a `dict` that assigns a bin ID of type `int` to a catalogue. We perform a selection on the `wlfs2_cat` FITS using the `[]` syntax, which returns a new view of the `FitsCatalog` with the given rowfilter applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogs = {i: wlfs2_cat[f'TOM_BIN_ID == {i}'] for i in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View have their own invididual `.visibility` property, but inherit the visibility of the base catalogue by default.\n",
    "\n",
    "Instead of the `[]` syntax, view can also be created using the `.where()` method, in which case the visibility can be given directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogs[3].visibility is vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `catalogs` is a simple mapping of integer bin IDs to instances of type `Catalog`. You can create such a mapping in any way you like; the values do not have to come from the same `FitsCatalog`, or even the same type of catalogue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the number of rows in tomographic bin 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to sum because FITS cannot tell the size a priori\n",
    "nrows = sum(page.size for page in catalogs[5])\n",
    "\n",
    "print(f'tomographic bin 5 contains {nrows:_} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.maps import PositionMap, ShearMap, map_catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to produce position and shear maps from the catalogues for each tomographic bin. *Heracles* can construct maps from individual catalogues, and it can map a whole set of catalogues all at once. Here we use the latter interface, which is available as the `map_catalogs()` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify which maps to make, we construct a mapping from names to objects that do the map-making. Each of these receives a list of columns that it reads, plus potentially some other options.\n",
    "\n",
    "For a standard 3x2pt analysis in harmonic space, we need\n",
    "\n",
    "* A position map (P) for angular clustering and galaxy-galaxy lensing;\n",
    "* A shear map (G) for cosmic shear and galaxy-galaxy lensing.\n",
    "\n",
    "We set that the shear maps should flip the sign of the \"G2\" column (`conjugate=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't repeat the lon and lat column every time\n",
    "lonlat = ('RIGHT_ASCENSION', 'DECLINATION')\n",
    "\n",
    "maps = {\n",
    "    'P': PositionMap(nside, *lonlat),\n",
    "    'G': ShearMap(nside, *lonlat, 'G1', 'G2', 'WEIGHT', conjugate=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we are able to create maps of the tomographic catalogues. We only need to pass in the catalogue and mappings constructed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = map_catalogs(maps, catalogs, parallel=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `data` mapping has keys consisting of a map ID (`P`, `G`) and a bin ID. Results from *Heracles* are always of this form, which we call \"toc dicts\", short for \"table of contents dictionaries\" from how the data was originally written to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.keys())[:8] + ['...']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a quick look at the maps for a tomographic bin ID, say 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.tight_layout()\n",
    "plt.sca(ax[0, 0])\n",
    "hp.cartview(data['P', i], title='P', cmap='binary', min=-1., max=4., hold=True,\n",
    "            lonra=[60, 150], latra=[20, 65])\n",
    "ax[0, 1].axis('off')\n",
    "plt.sca(ax[1, 0])\n",
    "hp.cartview(data['G', i][0], title='G1', cmap='RdGy', min=-4, max=4, hold=True,\n",
    "            lonra=[60, 150], latra=[20, 65])\n",
    "plt.sca(ax[1, 1])\n",
    "hp.cartview(data['G', i][1], title='G2', cmap='RdGy', min=-4, max=4, hold=True,\n",
    "            lonra=[60, 150], latra=[20, 65])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working in harmonic space, the real-space maps we created so far are not what we are actually after. We therefore transform them into harmonic-space maps (i.e. $a_{lm}$) using the `transform_maps()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.maps import transform_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alms = transform_maps(data, lmax=lmax, use_pixel_weights=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `alm` object is another toc dict with keys for map ID (`P`, `G_E`, `G_B`) and bin ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(alms.keys())[:9] + ['...']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-point statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to compute the two-point statistics in the form of angular power spectra. We simply call the `angular_power_spectrum()` function on the `alms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.twopoint import angular_power_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = angular_power_spectra(alms, lmax=lmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could limit the `cls` we want computed using the `include=` and `exclude=` parameters to `angular_power_specta()`, but here we have computed all combinations. They are very many, arranged in a toc dict with entries such as `('P', 'G_E', 5, 4)` for the position and *E*-mode angular power spectrum between bin IDs 5 and 4 (in order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cls.keys())[:6] + ['...'] + list(cls.keys())[-6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can take a meaningful look at the result, we must consider a number of observational effects that influence the angular power spectra. First is the so-called noise bias, which is owed to the fact that we are observing discrete positions and shears instead of continuous fields.\n",
    "\n",
    "In the near future, *Heracles* will provide theoretical values for all noise biases. For the time being, we can use the `random_noisebias()` function to estimate the noise bias from randomised position and shear maps instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.twopoint import random_noisebias\n",
    "\n",
    "# fix seed to always get the same result in this example (don't do that in production!)\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = random_noisebias(maps, catalogs, parallel=True, progress=True,\n",
    "                       lmax=lmax, use_pixel_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the noise biases computed, we can debias our angular power spectra by subtracting them. Since we do not need the biased `cls`, we compute the debiased ones in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.twopoint import debias_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_cls(cls, noisebias=nbs, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second observational effect is that we do not have data over the entire sky, but are limited by the survey footprint and visibility. This effect is modelled at the level of two-point statistics by the so-called mixing matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the mixing matrices requires separate maps for the visibility and shear weights in each tomographic bin. The mixing matrices for angular power spectra up to `lmax` require `2*lmax` angular modes themselves, so we double the resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside_mm = 2*nside\n",
    "lmax_mm = 2*lmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the same catalogues as before to create the visibility and weight maps, using the `map_catalogs()` function as before. Of course, we could have also computed all maps in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.maps import VisibilityMap, WeightMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visibility maps are taken as-is from catalogue, so no columns\n",
    "maps_mm = {\n",
    "    'V': VisibilityMap(nside_mm),\n",
    "    'W': WeightMap(nside_mm, *lonlat, 'WEIGHT'),\n",
    "}\n",
    "\n",
    "data_mm = map_catalogs(maps_mm, catalogs, parallel=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output has the same format as earlier, but now contains `V` and `W` maps as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_mm.keys())[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we transform the maps for the mixing matrices ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alms_mm = transform_maps(data_mm, progress=True,\n",
    "                         lmax=lmax_mm, use_pixel_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and compute their angular power spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cls_mm = angular_power_spectra(alms_mm, lmax=lmax_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the mixing matrices correctly, we must divide the kernels of the HEALPix discretisation (i.e. the pixel window function) from the measured angular power spectra, to obtain what would have been measured for a continuous field.  We can do so in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.twopoint import depixelate_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depixelate_cls(cls_mm, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the angular power spectra of visibility and weight maps available, we can compute all mixing matrices with the `mixing_matrices()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.twopoint import mixing_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = mixing_matrices(cls_mm, l1max=lmax, l2max=lmax, l3max=lmax_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mixing matrices are returned in a toc dict with slightly different names: They use a two letter code that indicates which angular power spectra are mixed by a given matrix:\n",
    "\n",
    "* `00` for `(P, P) → (P, P)`;\n",
    "* `0+` for `(P, E) → (P, E)` and `(P, B) → (P, B)`;\n",
    "* `++` for `(E, E) → (E, E)` and `(B, B) → (B, B)`;\n",
    "* `--` for `(E, E) → (B, B)` and `(B, B) → (E, E)`;\n",
    "* `+-` for `(E, B) → (E, B)`.\n",
    "\n",
    "For more details, see the paper by Brown, Castro & Taylor (2005). Note that the `+-` mixing matrix here is not the $W^{+-}$ matrix from said paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(mms.keys())[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add the effect of the HEALPix discretisation to the mixing matrices, so that the product of mixing matrices and expected angular power spectra models our observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.twopoint import pixelate_mms_healpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelate_mms_healpix(mms, nside, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the visibility and weight map for a bin ID, say 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 8))\n",
    "fig.tight_layout()\n",
    "plt.sca(ax[0])\n",
    "hp.cartview(data_mm['V', i], title='V', cmap='binary', hold=True,\n",
    "            lonra=[60, 150], latra=[20, 65])\n",
    "plt.sca(ax[1])\n",
    "hp.cartview(data_mm['W', i], title='W', cmap='binary', min=0, max=100, hold=True,\n",
    "            lonra=[60, 150], latra=[20, 65])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at one of the resulting mixing matrices, say the `++` one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mms['++', i, i], cmap='binary',\n",
    "            norm=mpl.colors.LogNorm(vmin=1e-4))\n",
    "plt.colorbar(pad=0.025, fraction=0.0465)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final piece of the puzzle is a set of theory angular power spectra that model the full sky signal. Here we use *CAMB* to get a quick and dirty approximation of what the proper theory spectra might look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camb\n",
    "from camb.sources import SplinedSourceWindow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the *CAMB* cosmology to match the *Flagship2* simulation, which is\n",
    "\n",
    "* $\\Omega_m = 0.319$,\n",
    "* $\\Omega_b = 0.049$,\n",
    "* $\\Omega_\\Lambda + \\Omega_\\gamma = 0.681$,\n",
    "* $A_s = 2.1 \\cdot 10^{-9}$,\n",
    "* $n_s = 0.96$,\n",
    "* $h = 0.67$.\n",
    "\n",
    "Also set some other properties that come straight from the *CAMBdemo* notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = camb.CAMBparams()\n",
    "pars.set_cosmology(H0=67., omch2=0.319*0.67**2, ombh2=0.049*0.67**2)\n",
    "pars.InitPower.set_params(As=2.1e-9, ns=0.96)\n",
    "pars.Want_CMB = False \n",
    "pars.NonLinear = camb.model.NonLinear_both\n",
    "pars.set_for_lmax(lmax, lens_potential_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the redshift distributions for the tomographic bins. For the real data, these will be provided by *OU-PHZ* in some *TBD* format. Here, we use the file from the *Flagship2* catalogue for *LE3-WL* without asking any further questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = fitsio.read('nz_wlfs2_dr1n_vis24.5_nomag.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the theory spectra of the galaxy number counts, we need the bias factor between matter and galaxies. This is a bias factor fitted to *Flagship2*, kindly provided by Isaac Tutusaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = nz['Z_MID']\n",
    "bz = 0.83070341 + 1.19054721*z - 0.92835749*z**2 + 0.42329232*z**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given redshift distributions and bias factor, we can construct the *CAMB* source distributions for positions (counts) and shears (lensing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "for i in range(len(catalogs)):\n",
    "    nz_i = nz[f'BIN{i}']\n",
    "    sources += [\n",
    "        SplinedSourceWindow(source_type='counts', z=z, W=nz_i, bias_z=bz),\n",
    "        SplinedSourceWindow(source_type='lensing', z=z, W=nz_i),\n",
    "    ]\n",
    "pars.SourceWindows = sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pars` we constructed above to compute the full sky theory spectra up to `lmax`, setting `raw_cl=True` to return unscaled $C_l$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = camb.get_results(pars)\n",
    "camb_cls = results.get_source_cls_dict(lmax=lmax, raw_cl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the factor that's needed to convert from convergence to shear $C_l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.arange(lmax+1)\n",
    "fl = -np.sqrt((l+2)*(l+1)*l*(l-1))\n",
    "fl /= np.clip(l*(l+1), 1, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the theory spectra for our observations, using the *CAMB* results and the mixing matrices we computed earlier. We store everything in a toc dict using the same format as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_cls = {}\n",
    "for i, s1 in enumerate(sources):\n",
    "    for j, s2 in enumerate(sources[i:]):\n",
    "        i1, i2 = i//2, (i+j)//2\n",
    "\n",
    "        cl = camb_cls[f'W{i+1}xW{i+j+1}']\n",
    "\n",
    "        if s1.source_type == 'counts' and s2.source_type == 'counts':\n",
    "            theory_cls['P', 'P', i1, i2] = mms['00', i1, i2] @ cl\n",
    "        elif s1.source_type == 'lensing' and s2.source_type == 'lensing':\n",
    "            theory_cls['G_E', 'G_E', i1, i2] = mms['++', i1, i2] @ (cl*fl**2)\n",
    "            theory_cls['G_B', 'G_B', i1, i2] = mms['--', i1, i2] @ (cl*fl**2)\n",
    "        elif s1.source_type == 'counts' and s2.source_type == 'lensing':\n",
    "            theory_cls['P', 'G_E', i1, i2] = mms['0+', i1, i2] @ (cl*fl)\n",
    "            theory_cls['P', 'G_B', i1, i2] = np.zeros_like(cl)\n",
    "        elif s1.source_type == 'lensing' and s2.source_type == 'counts':\n",
    "            theory_cls['P', 'G_E', i2, i1] = mms['0+', i2, i1] @ (cl*fl)\n",
    "            theory_cls['P', 'G_B', i2, i1] = np.zeros_like(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without much further ado, let's plot the results for positions and shears.  Fortunately, *Heracles* has plot routines which make this very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heracles.plot import postage_stamps\n",
    "from heracles.util import toc_filter\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = np.sqrt((2*l+1)/(4*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postage_stamps([toc_filter(cls, [(\"G_E\", \"G_E\"), (\"G_B\", \"G_B\")]),\n",
    "                toc_filter(theory_cls, [(\"G_E\", \"G_E\"), (\"G_B\", \"G_B\")])],\n",
    "               [toc_filter(cls, [(\"P\", \"P\")]),\n",
    "                toc_filter(theory_cls, [(\"P\", \"P\")])],\n",
    "               shift_transpose=2, hatch_empty=True, scale=nat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postage_stamps([toc_filter(cls, [(\"P\", \"G_E\"), (\"P\", \"G_B\")]),\n",
    "                toc_filter(theory_cls, [(\"P\", \"G_E\"), (\"P\", \"G_B\")])],\n",
    "               scale=nat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While agreement is not perfect, it's good enough, given how haphazardly we have performed the analysis and modelling of the expectation. We can certainly do better: For example, the missing power in the clustering signal at the lower end is likely due to the finite box size of the simulation, and associated lack of large-scale density perturbations (hat tip to Alex Hall for pointing this out). And there are intrinsic alignments in the simulation, but not in the theory. All of this and more must be modelled properly in a serious analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
