{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance for Angular Power Spectra with *Heracles*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how *Heracles* computes an estimate of the covariance of the two-point statistics from a 3Ã—2pt catalogue using the DICES method. This tutorial is heavily based on the summary statisitcs tutorial so we will reproduce the results found in said tutorial without going into the details of the analysis. We will then show how to compute the covariance of the angular power spectra using *Heracles*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Important note**\n",
    "\n",
    "This notebook is only meant to give you an idea of **how *Heracles* works**.\n",
    "\n",
    "It does **not** show everything that *Heracles* can do.\n",
    "\n",
    "**This is a toy, treat it is such!**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006a633e284e4a57bd96d8262c552fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import heracles\n",
    "import heracles.healpy\n",
    "from heracles.notebook import Progress\n",
    "\n",
    "# Covariance code\n",
    "import heracles.dices as dices\n",
    "\n",
    "import helpers\n",
    "\n",
    "with Progress(\"example data\") as progress:\n",
    "    helpers.get_example_data(progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the resolution parameter for measuring spectra from *HEALPix* maps.  Here, we use `nside = 128` since that is the resolution at which the example data has been created. A value `lmax` of approximate 1.5x `nside` is fairly safe in terms of errors introduced by *HEALPix*. For the purpose of this tutorial we will only use 3 tomographic bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nside = 128\n",
    "lmax = 140\n",
    "nbins = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we will use the same data as in the summary statistics tutorial. Note that the maps generated in the summary statistics tutorial might have a different resolution. Therefore we will have to up/down-scale them accordingly. Doing so, unfortunately destroys the metadata of the maps. Therefore we will have to manually re-enter the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from heracles.healpy import HealpixMapper\n",
    "from heracles.fields import Positions, Shears, Visibility, Weights\n",
    "\n",
    "data_maps = heracles.read_maps(\"example-data_maps.fits\")\n",
    "mapper = HealpixMapper(nside=nside, lmax=lmax)\n",
    "fields = {\n",
    "    \"POS\": Positions(mapper, mask=\"VIS\"),\n",
    "    \"SHE\": Shears(mapper, mask=\"WHT\"),\n",
    "    \"VIS\": Visibility(mapper),\n",
    "    \"WHT\": Weights(mapper),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_maps = heracles.read_maps(\"example-data_maps.fits\")\n",
    "for key in list(data_maps.keys()):\n",
    "    f, i = key\n",
    "    if i <= nbins - 1:\n",
    "        _map = data_maps[key]\n",
    "        meta = _map.dtype.metadata\n",
    "        new_map = hp.ud_grade(_map, nside)\n",
    "        heracles.update_metadata(\n",
    "            new_map,\n",
    "            nside=nside,\n",
    "            lmax=lmax,\n",
    "            bias=meta[\"bias\"],\n",
    "            fsky=meta[\"fsky\"],\n",
    "            spin=meta[\"spin\"],\n",
    "        )\n",
    "        data_maps[key] = new_map\n",
    "    else:\n",
    "        data_maps.pop(key)\n",
    "\n",
    "# load the FITS mask\n",
    "vis_map = hp.read_map(\"vmap.fits.gz\")\n",
    "vis_map[vis_map == hp.UNSEEN] = 0.0\n",
    "vis_map = hp.ud_grade(vis_map, nside)\n",
    "heracles.update_metadata(\n",
    "    vis_map,\n",
    "    nside=nside,\n",
    "    lmax=lmax,\n",
    "    bias=0.0,\n",
    "    fsky=meta[\"fsky\"],\n",
    "    spin=0,\n",
    ")\n",
    "vis_maps = {}\n",
    "for key in list(data_maps.keys()):\n",
    "    f, i = key\n",
    "    if f == \"POS\":\n",
    "        f = \"VIS\"\n",
    "    if f == \"SHE\":\n",
    "        f = \"WHT\"\n",
    "    key = (f, i)\n",
    "    vis_maps[key] = vis_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental idea behind Jackknife approaches is to generate an ensemble of angular power spectra by leaving out one of the regions at a time. The covariance of the angular power spectra can then be estimated from the variance of the ensemble. Therefore, the first step is to divide the mask of the survey into regions. In order to do so, in this tutorial we will make use of the SkySegmentor library. However, any library that segments the sky into regions can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import skysegmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "jk_maps = {}\n",
    "Njk = 30\n",
    "jk_map = skysegmentor.segmentmapN(vis_map, Njk)\n",
    "for key in list(vis_maps.keys()):\n",
    "    jk_maps[key] = jk_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hp.mollview(jk_maps[(\"VIS\", 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-point statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the computation of the two-point statistics was already covered in the summary statistics tutorial, we will not go into the details of the analysis. We will simply load the results from the summary statistics tutorial and use them to compute the covariance of the angular power spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cls0 = dices.jackknife_cls(data_maps, vis_maps, jk_maps, fields, nd=0)[()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, in this tutorial we will limit ourselves to loading the thoeory power spectra from the summary statistics tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "theory = heracles.read(\"example-theory.fits\")\n",
    "theory_cls = {}\n",
    "for key in list(cls0.keys()):\n",
    "    theory_cls[key] = theory[key][..., : lmax + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the ensemble of angular power spectrum effectively boils down to repeating the process presented in the two-point statistics section removing one of the jackknife regions at a time. However, a couple of extra considerations have to be made.\n",
    "\n",
    "\n",
    "When computing the angular power spectra from catalogues, removing one of the jackknife regions changes the sample variance of the angular power spectra by a factor of \n",
    "$$\n",
    "b_{jk} = b (1-\\frac{1}{N})\n",
    "$$\n",
    "\n",
    "Moreover, removing of the jackknife regions also changes the footprint of the survey which can introduce additional mixing betweeen E- and B-modes. Heracles is equiped with a mask correction routine that corrects for this effect by transforming the angular power spectra to real space, dividing the correlation function of the ratio of new footprint to the old footprint and transforming back to harmonic space. \n",
    "$$\n",
    " C_\\ell \\rightarrow \\xi(\\theta) \\\\\n",
    " M_\\ell \\rightarrow \\xi_m(\\theta) \\\\\n",
    " M^{\\rm jk}(\\theta) \\rightarrow \\xi^{\\rm jk}_m(\\theta) \\\\\n",
    "$$\n",
    "$$\n",
    "\\bar{\\xi}(\\theta) = \\xi(\\theta) \\frac{\\xi_m(\\theta)}{\\xi^{\\rm jk}_m(\\theta)} \\\\\n",
    "$$\n",
    "$$\n",
    "\\bar{\\xi}(\\theta) \\rightarrow \\bar{C}_\\ell\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cls1 = dices.jackknife_cls(data_maps, vis_maps, jk_maps, fields, nd=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add numerically stability to our computations, we will also bin the ensemble of angular power spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nlbins = 10\n",
    "ell = np.arange(lmax + 1)\n",
    "ledges = np.logspace(np.log10(10), np.log10(lmax), nlbins + 1)\n",
    "lgrid = (ledges[1:] + ledges[:-1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cqs0 = heracles.binned(cls0, ledges)\n",
    "cqs1 = heracles.binned(cls1, ledges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife Covariance\n",
    "\n",
    "The delete-one covariance is computed by measuring the covariance matrix of the ensemble of delete-one angular power spectra. The covariance matrix of an ensemble of $K$ vector variables $x \\in \\mathbb{R}^N$ is defined as:\n",
    "$$\n",
    "\\mathbb{C}_{ij} = \\mathbb{E} \\left[ (x_i - \\bar{x_i}) (x_j - \\bar{x_j})^T \\right]_k \\, ,\n",
    "$$\n",
    "where $\\bar{x_i} = \\mathbb{E}[x_{ik}]_k = \\frac{1}{K} \\sum_k^K x_{ik}$ is the mean over the ensemble. Therefore, one can define any covariance matrix as an expectation over an ensemble of matrices with entries:\n",
    "$$\n",
    "W(x)_{ijk} = (x_{ik} - \\bar{x_i}) (x_{jk} - \\bar{x_j}) \\, .\n",
    "$$\n",
    "such that $\\mathbb{C}_{ij} = \\mathbb{E} [W(x)_{ijk}]_k$. Therefore and associating $x$ with the angular power spectra, the computation of the delete-one covariance is then given by:\n",
    "$$\n",
    "\\mathbb{C}^{\\rm JK}_{ij} = (K-1) \\mathbb{E} [W(x)_{ijk}]_k \\, .\n",
    "$$\n",
    "\n",
    "Analyzing the equation above we can understand better the Jackknife approach. As we increase the number of jackknife regions, the size of each indiviual regions decreases meaning that\n",
    "$$\n",
    "\\rm{lim}_{K \\rightarrow \\infty} (x_{ik} - \\bar{x_i}) = 0 \\, ,\n",
    "$$\n",
    "such that $W_{ijk} \\rightarrow 0$ and thus $\\mathbb{E} [W_{ijk}]_k \\rightarrow 0$.\n",
    "However, the prefactor $(K-1)$ ensures that the Jackknige covariance doesn't vanish as $K$ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cov_jk = dices.jackknife_covariance(cqs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    cov_jk[(\"POS\", \"POS\", \"POS\", \"POS\", 1, 1, 1, 1)][:, :],\n",
    "    vmin=-2.5 * 10**-14,\n",
    "    vmax=2.5 * 10**-14,\n",
    "    cmap=\"seismic\",\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.title(\"Delete-1 covariance\")\n",
    "plt.ylabel(r\"$\\ell$\")\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debiasing\n",
    "\n",
    "It can be shown that the Jackknife covariance errors (i.e. its diagonal entries) tend to be biased high. In other words, the Jackknife covariance matrix overestimates the variances of the angular power spectra. In order to address this, the DICES covariances introduces a second ensemble of angular power spectra, the delete-two ensemble. The delete-two ensemble is computed by removing two jackknife regions at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cls2 = dices.jackknife_cls(data_maps, vis_maps, jk_maps, fields, nd=2)\n",
    "cqs2 = heracles.binned(cls2, ledges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once, the delete-two ensemble is computed, the correction can be obtained by computing the expressions:\n",
    "$$\n",
    "q_{p} = K x_0 - (K-1) (x_{1 \\, k} + x_{1 \\, k'}) + (K-2) x_{2 \\, k} \\, ,\n",
    "$$\n",
    "where $x_0$ denotes the concatenated angular power spectra of the full survey, $x_{1 \\, k}$ and $x_{1 \\, k'}$ denote the concatenated angular power spectra of the survey with the $k$-th and $k'$-th jackknife regions removed respectively, and $x_{2 \\, p}$ denotes the concatenated angular power spectra of the survey with both the $k$-th and $k'$-th jackknife regions removed. Note that $p$ is an iterator that runs from 1 to $K(K-1)/2$ related to the combinations of $k$ and $k'$. \n",
    "\n",
    "Now we need to compute the variance of the q-ensemble. In order to do so, we can use the same framework as for the delete-one matrices substituting $q$ for $x$ in the expression for $W$. The correction is then given by:\n",
    "$$\n",
    "Q_{ij} = \\frac{K(K-1)-2}{2K(K+1)} \\mathbb{E} [W(q)_{ijp}]_{p} \\, .\n",
    "$$\n",
    "\n",
    "Finally the debiased covariance matrix is given by:\n",
    "$$\n",
    "\\mathbb{C}^{\\rm debiased} = \\mathbb{C}^{\\rm JK} - Q \\, .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "debiased_cov_jk = dices.debias_covariance(\n",
    "    cov_jk,\n",
    "    cqs0,\n",
    "    cqs1,\n",
    "    cqs2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    debiased_cov_jk[(\"POS\", \"POS\", \"POS\", \"POS\", 1, 1, 1, 1)][:, :],\n",
    "    vmin=-2.5 * 10**-14,\n",
    "    vmax=2.5 * 10**-14,\n",
    "    cmap=\"seismic\",\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.title(\"Debiased Covariance\")\n",
    "plt.ylabel(r\"$\\ell$\")\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrinkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of debiasing, DICES also gives the user the option to shrink their covariance estimate to given target. This additional step can great help in reducing the noise in the covariance matrix. Moreover, shrinking towards a Gaussian estimate of the covariance has been shown to greatly help in reproducing the eigen-values of sample covariances from simulations. Thus, from here onward we will assume a Gaussian target given by:\n",
    "$$\n",
    "\\mathbb{C}^{\\rm target}_{abcd} = \\frac{C_\\ell^{ac} C_\\ell^{bd} + C_\\ell^{ad} C\\ell^{bc}}{2\\ell+1}  \\, .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gauss_cov = dices.gaussian_covariance(cqs0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    gauss_cov[(\"POS\", \"POS\", \"POS\", \"POS\", 1, 1, 1, 1)][:, :],\n",
    "    vmin=1 * 10**-14,\n",
    "    vmax=5 * 10**-13,\n",
    "    cmap=\"seismic\",\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.title(\"Target\")\n",
    "plt.ylabel(r\"$\\ell$\")\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the target has been set, the shrunk covariance is given by:\n",
    "$$\n",
    "\\mathbb{C}^{\\rm shrunk} =  \\lambda  \\mathbb{C}^{\\rm target} + (1-\\lambda) \\mathbb{C}^{\\rm debiased}  \\, ,\n",
    "$$\n",
    "where $\\lambda$ is the shrinkage factor and $\\mathbb{C}^{\\rm target}$ is the target covariance matrix. We set the diagonal entries of target covariance to those of the debiased covariance matrix. This is done in order to ensure that the variances of the angular power spectra are not shrunk.\n",
    "$$\n",
    "\\mathbb{C}^{\\rm target}_{ij} \\rightarrow \\mathbb{C}^{\\rm debiased}_{ij} \\,  \\rm{if} \\,  i = j.\n",
    "$$\n",
    "Moreover, we modify the off-diagonal entries of the target as:\n",
    "$$\n",
    "\\mathbb{C}^{\\rm target}_{ij} \\rightarrow \\mathbb{C}^{\\rm target}_{ij} \\frac{\\sqrt{\\mathbb{C}^{\\rm debiased}_{ii} \\mathbb{C}^{\\rm debiased}_{jj}}}{\\sqrt{\\mathbb{C}^{\\rm target}_{ii} \\mathbb{C}^{\\rm target}_{jj}}} \\,  \\rm{if} \\,  i \\neq j.\n",
    "$$\n",
    "\n",
    "Of course, the main challenge of shrinkage is finding the optimal shrinkage factor. Heracles currently provides a routine to compute an estimate of the optimal shrinkage factor based of the sample variace of the Jackknife covariance matrix computed as follows. First, $C_\\ell$'s in the ensemble as well as the target covariance are concatenated to form a single vector and matrix. Then, the mean and variance of the W-matrices associated with the concatenated vectors are computed.\n",
    "$$\n",
    "\\bar{W}(x)_{ij} = \\mathbb{E}[W(x)_{ijk}]_k \\, , \n",
    "$$\n",
    "$$\n",
    "\\mathbb{C}_{i_1 j_1 i_2 j_2}^{W} = \\frac{n^2}{(n-1)^3} \\, \\mathbb{E}[(W(x)_{i1 j1 k}-\\bar{W}(x)_{i1 j1 })(W(x)_{i2 j2 k}-\\bar{W}(x)_{i2 j2})] \\, . \n",
    "$$\n",
    "\n",
    "\n",
    "We now express the shrinkage factor as:\n",
    "$$\n",
    "\\lambda = \\frac{\\sum_{ij}^{i \\neq j} \\alpha_{ij}}{\\sum_{ij}^{i \\neq j} \\beta_{ij}}\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "\\alpha_{ij} = \\mathbb{C}_{i j i j}^{W} - \\mathbb{C}\\rm{orr}^{\\rm target}_{ij}  f_{ij} \\, ,\n",
    "$$\n",
    "$$\n",
    "\\beta_{ij} = \\left(\\mathbb{C}^{\\rm debiased}_{ij} - \\mathbb{C}\\rm{orr}^{\\rm target}_{ij} \\sqrt{\\mathbb{C}^{\\rm debiased}_{ii} \\mathbb{C}^{\\rm debiased}_{jj}} \\right)^2\\, ,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "f_{ij} = \\frac{1}{2} \\left[ \\sqrt{\\frac{\\bar{W}(x)_{jj}}{\\bar{W}(x)_{ii}}} \\mathbb{C}_{iiij}^{W} + \\sqrt{\\frac{\\bar{W}(x)_{ii}}{\\bar{W}(x)_{jj}}} \\mathbb{C}_{jjij}^{W} \\right] \\, .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "shrinkage_factor = dices.shrinkage_factor(cqs1, gauss_cov)\n",
    "print(shrinkage_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "shrunk_cov_jk = dices.shrink(\n",
    "    cov_jk,\n",
    "    gauss_cov,\n",
    "    shrinkage_factor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    shrunk_cov_jk[(\"POS\", \"POS\", \"POS\", \"POS\", 1, 1, 1, 1)][:, :],\n",
    "    vmin=-2.5 * 10**-14,\n",
    "    vmax=2.5 * 10**-14,\n",
    "    cmap=\"seismic\",\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.title(\"Shrunk Covariance\")\n",
    "plt.ylabel(r\"$\\ell$\")\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the DICES covariance is obtained by imposing the correlation structure of the shrunk covariance to the debiased covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dices_cov = dices.impose_correlation(debiased_cov_jk, shrunk_cov_jk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(10, 15))\n",
    "\n",
    "# Flattened cov_jk\n",
    "flat_cov_jk = dices.flatten(cov_jk)\n",
    "flat_corr_jk = flat_cov_jk / np.sqrt(\n",
    "    np.diag(flat_cov_jk)[:, None] * np.diag(flat_cov_jk)[None, :]\n",
    ")\n",
    "im1 = axes[0].imshow(flat_corr_jk, cmap=\"seismic\", vmin=-1, vmax=1)\n",
    "axes[0].set_title(\"Jackknife Covariance\")\n",
    "\n",
    "# Flattened debiased_cov_jk\n",
    "flat_debiased_cov = dices.flatten(debiased_cov_jk)\n",
    "flat_corr_debiased = flat_debiased_cov / np.sqrt(\n",
    "    np.diag(flat_debiased_cov)[:, None] * np.diag(flat_debiased_cov)[None, :]\n",
    ")\n",
    "im2 = axes[1].imshow(flat_corr_debiased, cmap=\"seismic\", vmin=-1, vmax=1)\n",
    "axes[1].set_title(\"Debiased Covariance\")\n",
    "\n",
    "# Flattened shrunk_cov\n",
    "flat_shrunk_cov = dices.flatten(shrunk_cov_jk)\n",
    "flat_corr_shrunk = flat_shrunk_cov / np.sqrt(\n",
    "    np.diag(flat_shrunk_cov)[:, None] * np.diag(flat_shrunk_cov)[None, :]\n",
    ")\n",
    "im3 = axes[2].imshow(flat_corr_shrunk, cmap=\"seismic\", vmin=-1, vmax=1)\n",
    "axes[2].set_title(\"Shrunk Covariance\")\n",
    "\n",
    "# Flattened dices_cov\n",
    "flat_dices_cov = dices.flatten(dices_cov)\n",
    "flat_corr_dices = flat_dices_cov / np.sqrt(\n",
    "    np.diag(flat_dices_cov)[:, None] * np.diag(flat_dices_cov)[None, :]\n",
    ")\n",
    "im3 = axes[3].imshow(flat_corr_dices, cmap=\"seismic\", vmin=-1, vmax=1)\n",
    "axes[3].set_title(\"DICES Covariance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    2 * (nbins - 1),\n",
    "    nbins - 1,\n",
    "    figsize=(9, 9),\n",
    "    gridspec_kw={\"height_ratios\": [3, 1, 3, 1, 3, 1]},\n",
    ")\n",
    "\n",
    "for i in range(1, nbins):\n",
    "    for j in range(1, i):\n",
    "        ax[j - 1, i - 1].axis(\"off\")\n",
    "        ax[j, i - 1].axis(\"off\")\n",
    "        ax[3, 2].axis(\"off\")\n",
    "    for j in range(i, nbins):\n",
    "        key = (\"POS\", \"POS\", i, j)\n",
    "        cov_key = (\"POS\", \"POS\", \"POS\", \"POS\", i, j, i, j)\n",
    "        cov = dices_cov[cov_key]\n",
    "        c = cqs0[key].array\n",
    "        t = theory_cls[key]\n",
    "        t_itp = np.interp(lgrid, ell, t)\n",
    "        err = np.sqrt(np.diag(cov))\n",
    "        ax[2 * (j - 1), i - 1].errorbar(\n",
    "            lgrid, c, yerr=err, c=\"C0\", lw=1.5, zorder=3.0, alpha=0.5\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].plot(ell[10:], t[10:], c=\"C0\", lw=1.0, zorder=4.0)\n",
    "        ax[2 * (j - 1), i - 1].axhline(0.0, c=\"k\", lw=0.8, zorder=-1)\n",
    "        ax[2 * (j - 1) + 1, i - 1].errorbar(\n",
    "            lgrid,\n",
    "            (c - t_itp) / t_itp,\n",
    "            yerr=np.abs(err / t_itp),\n",
    "            fmt=\".\",\n",
    "            c=\"C0\",\n",
    "            lw=1.5,\n",
    "            zorder=1.0,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[2 * (j - 1) + 1, i - 1].axhline(0.0, c=\"k\", lw=0.8, zorder=-1)\n",
    "\n",
    "        ax[2 * (j - 1), i - 1].tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "        ax[2 * (j - 1), i - 1].set_yscale(\n",
    "            \"symlog\", linthresh=1e-7, linscale=0.45, subs=np.arange(0.1, 1.0, 0.1)\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].set_ylim(-3e-7, 5e-6)\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_yscale(\n",
    "            \"symlog\", linthresh=0.1, linscale=0.45, subs=np.arange(0.1, 1.0, 0.1)\n",
    "        )\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_ylim(-10, 10)\n",
    "\n",
    "        ax[2 * (j - 1), i - 1].set_xscale(\"log\")\n",
    "        ax[2 * (j - 1), i - 1].set_xlim(5, lmax * 2)\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_xscale(\"log\")\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_xlim(5, lmax * 2)\n",
    "        if i > 1:\n",
    "            ax[2 * (j - 1), i - 1].set_yticklabels([])\n",
    "            ax[2 * (j - 1) + 1, i - 1].set_yticklabels([])\n",
    "\n",
    "\n",
    "fig.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.0, hspace=0.0)\n",
    "\n",
    "fig.supxlabel(\"angular mode $\\\\ell$\", y=-0.05, va=\"top\")\n",
    "fig.supylabel(\"galaxy clustering $C_\\\\ell$\", x=-0.1, ha=\"right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    2 * (nbins - 1),\n",
    "    nbins - 1,\n",
    "    figsize=(9, 9),\n",
    "    gridspec_kw={\"height_ratios\": [3, 1, 3, 1, 3, 1]},\n",
    ")\n",
    "\n",
    "for i in range(1, nbins):\n",
    "    for j in range(1, i):\n",
    "        ax[j - 1, i - 1].axis(\"off\")\n",
    "        ax[j, i - 1].axis(\"off\")\n",
    "        ax[3, 2].axis(\"off\")\n",
    "    for j in range(i, nbins):\n",
    "        key = (\"SHE\", \"SHE\", i, j)\n",
    "        cov_key = (\"SHE\", \"SHE\", \"SHE\", \"SHE\", i, j, i, j)\n",
    "        e_cov = dices_cov[cov_key][0, 0, 0, 0, :, :]\n",
    "        e_err = np.sqrt(np.diag(e_cov))\n",
    "        b_cov = dices_cov[cov_key][1, 1, 1, 1, :, :]\n",
    "        b_err = np.sqrt(np.diag(b_cov))\n",
    "        e_c = cqs0[key][0, 0, :]\n",
    "        b_c = cqs0[key][1, 1, :]\n",
    "        e_t = theory_cls[key][0, 0, :]\n",
    "        b_t = theory_cls[key][1, 1, :]\n",
    "        e_t_itp = np.interp(lgrid, ell, e_t)\n",
    "        b_t_itp = np.interp(lgrid, ell, b_t)\n",
    "        ax[2 * (j - 1), i - 1].errorbar(\n",
    "            lgrid,\n",
    "            cqs0[key][0, 0, :],\n",
    "            yerr=e_err,\n",
    "            c=\"C0\",\n",
    "            lw=1.5,\n",
    "            zorder=3.0,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].plot(ell[10:], e_t[10:], c=\"C0\", lw=1.0, zorder=4.0)\n",
    "        ax[2 * (j - 1) + 1, i - 1].errorbar(\n",
    "            lgrid,\n",
    "            (e_c - e_t_itp) / e_t_itp,\n",
    "            yerr=e_err / e_t_itp,\n",
    "            fmt=\".\",\n",
    "            c=\"C0\",\n",
    "            lw=1.5,\n",
    "            zorder=1.0,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].errorbar(\n",
    "            lgrid,\n",
    "            b_c,\n",
    "            yerr=b_err,\n",
    "            c=\"C1\",\n",
    "            lw=1.5,\n",
    "            zorder=1.0,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].plot(\n",
    "            ell[10:],\n",
    "            b_t[10:],\n",
    "            c=\"C1\",\n",
    "            lw=1.0,\n",
    "            zorder=2.0,\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].axhline(0.0, c=\"k\", lw=0.8, zorder=-1)\n",
    "        ax[2 * (j - 1) + 1, i - 1].axhline(0.0, c=\"k\", lw=0.8, zorder=-1)\n",
    "        ax[2 * (j - 1), i - 1].tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "        ax[2 * (j - 1), i - 1].set_yscale(\n",
    "            \"symlog\", linthresh=1e-10, linscale=0.45, subs=np.arange(0.1, 1.0, 0.1)\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].set_ylim(-3e-9, 5e-9)\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_yscale(\n",
    "            \"symlog\", linthresh=0.1, linscale=0.45, subs=np.arange(0.1, 1.0, 0.1)\n",
    "        )\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_ylim(-2.5, 2.5)\n",
    "\n",
    "        ax[2 * (j - 1), i - 1].set_xscale(\"log\")\n",
    "        ax[2 * (j - 1), i - 1].set_xlim(5, lmax * 2)\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_xscale(\"log\")\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_xlim(5, lmax * 2)\n",
    "        if i > 1:\n",
    "            ax[2 * (j - 1), i - 1].set_yticklabels([])\n",
    "            ax[2 * (j - 1) + 1, i - 1].set_yticklabels([])\n",
    "ax[0, 0].xaxis.get_major_locator().set_params(numticks=99)\n",
    "ax[0, 0].xaxis.get_minor_locator().set_params(\n",
    "    numticks=99, subs=np.arange(0.1, 1.0, 0.1)\n",
    ")\n",
    "# ax[0, 0].set_yscale(\n",
    "#    \"symlog\", linthresh=1e-10, linscale=0.45, subs=np.arange(0.1, 1.0, 0.1)\n",
    "# )\n",
    "# ax[0, 0].set_ylim(-3e-7, 5e-7)\n",
    "\n",
    "fig.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.0, hspace=0.0)\n",
    "\n",
    "fig.supxlabel(\"angular mode $\\\\ell$\", y=-0.05, va=\"top\")\n",
    "fig.supylabel(\"cosmic shear $C_\\\\ell$\", x=-0.1, ha=\"right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    2 * (nbins - 1),\n",
    "    (nbins - 1),\n",
    "    figsize=(9, 9),\n",
    "    gridspec_kw={\"height_ratios\": [3, 1, 3, 1, 3, 1]},\n",
    ")\n",
    "\n",
    "for i in range(1, nbins):\n",
    "    for j in range(1, nbins):\n",
    "        key = (\"POS\", \"SHE\", i, j)\n",
    "        cov_key = (\"POS\", \"SHE\", \"POS\", \"SHE\", i, j, i, j)\n",
    "        e_cov = dices_cov[cov_key][0, 0, :, :]\n",
    "        e_err = np.sqrt(np.diag(e_cov))\n",
    "        b_cov = dices_cov[cov_key][1, 1, :, :]\n",
    "        b_err = np.sqrt(np.diag(b_cov))\n",
    "        e_c = cqs0[key][0, :]\n",
    "        b_c = cqs0[key][1, :]\n",
    "        e_t = theory_cls[key][0, :]\n",
    "        b_t = theory_cls[key][1, :]\n",
    "        e_t_itp = np.interp(lgrid, ell, e_t)\n",
    "        b_t_itp = np.interp(lgrid, ell, b_t)\n",
    "\n",
    "        ax[2 * (j - 1), i - 1].errorbar(\n",
    "            lgrid,\n",
    "            e_c,\n",
    "            yerr=e_err,\n",
    "            c=\"C0\",\n",
    "            lw=1.5,\n",
    "            zorder=3.0,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].plot(ell[10:], e_t[10:], c=\"C0\", lw=1.0, zorder=4.0)\n",
    "        ax[2 * (j - 1) + 1, i - 1].errorbar(\n",
    "            lgrid,\n",
    "            (e_c - e_t_itp) / e_t_itp,\n",
    "            yerr=e_err / np.abs(e_t_itp),\n",
    "            fmt=\".\",\n",
    "            c=\"C0\",\n",
    "            lw=1.5,\n",
    "            zorder=1.0,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].errorbar(\n",
    "            lgrid,\n",
    "            b_c,\n",
    "            yerr=b_err,\n",
    "            c=\"C1\",\n",
    "            lw=1.5,\n",
    "            zorder=1.0,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].plot(ell[10:], b_t[10:], c=\"C1\", lw=1.0, zorder=2.0)\n",
    "        ax[2 * (j - 1), i - 1].axhline(0.0, c=\"k\", lw=0.8, zorder=-1)\n",
    "        ax[2 * (j - 1) + 1, i - 1].axhline(0.0, c=\"k\", lw=0.8, zorder=-1)\n",
    "        ax[2 * (j - 1), i - 1].tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "\n",
    "        ax[2 * (j - 1), i - 1].set_yscale(\n",
    "            \"symlog\", linthresh=1e-9, linscale=0.45, subs=np.arange(0.1, 1.0, 0.1)\n",
    "        )\n",
    "        ax[2 * (j - 1), i - 1].set_ylim(-8e-7, 8e-7)\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_yscale(\n",
    "            \"symlog\",\n",
    "            linthresh=0.1,\n",
    "            linscale=0.1,\n",
    "        )\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_ylim(-10, 10)\n",
    "\n",
    "        ax[2 * (j - 1), i - 1].set_xscale(\"log\")\n",
    "        ax[2 * (j - 1), i - 1].set_xlim(5, lmax * 2)\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_xscale(\"log\")\n",
    "        ax[2 * (j - 1) + 1, i - 1].set_xlim(5, lmax * 2)\n",
    "        if i > 1:\n",
    "            ax[2 * (j - 1), i - 1].set_yticklabels([])\n",
    "            ax[2 * (j - 1) + 1, i - 1].set_yticklabels([])\n",
    "\n",
    "# ax[0, 0].set_xscale(\"log\")\n",
    "# ax[0, 0].set_xlim(1 / 2, lmax * 2)\n",
    "ax[0, 0].xaxis.get_major_locator().set_params(numticks=99)\n",
    "ax[0, 0].xaxis.get_minor_locator().set_params(\n",
    "    numticks=99, subs=np.arange(0.1, 1.0, 0.1)\n",
    ")\n",
    "# ax[0, 0].set_yscale(\n",
    "#    \"symlog\", linthresh=1e-9, linscale=0.45, subs=np.arange(0.1, 1.0, 0.1)\n",
    "# )\n",
    "# ax[0, 0].set_ylim(-8e-7, 4e-7)\n",
    "\n",
    "fig.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.0, hspace=0.0)\n",
    "\n",
    "fig.supxlabel(\"angular mode $\\\\ell$\", y=-0.05, va=\"top\")\n",
    "fig.supylabel(\"galaxy--galaxy lensing $C_\\\\ell$\", x=-0.1, ha=\"right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gitd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
